# AGI - Artificial General Intelligence üöÄ   

### A curated list of tools and resources to help you accelerate your journey toward building AGI ü§ñ 

Generative artificial intelligence is a branch of AI focused on using machine learning algorithms to generate new content such as images, video, text, and audio. The goal is for AI systems to create unique, original artifacts that seem as if they were created by humans.

Some examples of generative AI include:

* **Generative Adversarial Networks ([GANs](https://developers.google.com/machine-learning/gan)):**    GANs use two neural networks, a generator and a discriminator, that compete against each other to create new data samples. GANs have been used to generate photorealistic images, human faces, works of art, and more.



* **Variational Autoencoders ([VAEs](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)):** VAEs are neural networks used for unsupervised learning of compressed latent representations of data. They have been used to generate new data samples such as images, handwriting, and speech.

* **Text Generation:** Models like GPT-3 can generate paragraphs of coherent text, poetry, articles, and scripts after being trained on massive datasets.

* **Deepfakes ([Link](https://medium.com/swlh/deepfake-everything-you-need-to-know-about-it-3aa8a0ab6c05)):** Deep learning techniques can manipulate or generate visual and audio content with a high potential for misuse. Models can generate fake images, videos, and speech that seem authentic.

* **Reinforcement Learning from Human Feedback (RLHF)([Link](https://huggingface.co/blog/rlhf)):** Algorithms like DeepMind's AlphaGo have gotten smarter at playing complex games by competing against themselves to develop advanced strategies.

* **Neural Style Transfer ([Link](https://www.tensorflow.org/tutorials/generative/style_transfer#:~:text=Neural%20style%20transfer%20is%20an,of%20the%20style%20reference%20image.)):** This technique uses neural networks to transfer the style of one image onto the content of another image. It has been used by apps like Prisma, Dreamscope, and Style2Paints to generate unique works of art.

The goal of generative AI is to give machines a degree of creative ability and push the boundaries of what AI can accomplish. But it also introduces risks around the plausible spread of misinformation that we must consider seriously. Overall, generative AI is an exciting and fast-moving field of research.

# **LLMs - Large language models** üíª 

LLMs or Large Language Models are neural networks trained on massive amounts of text data to recognize patterns and generate natural language. They are a type of self-supervised learning model, meaning they learn by making predictions based on vast amounts of unlabeled data.

### **Some key characteristics of LLMs include:**

* They are trained on huge datasets that can contain billions of words. The larger the dataset, the more knowledge and capabilities the LLM can acquire.

* They employ the transformer architecture, which uses an attention mechanism to understand the context and relationships between words in a sentence. This allows the model to handle long-range dependencies in language.

* They are usually pretrained on a general language modeling task and then fine-tuned for more specific downstream tasks like question answering, text summarization, and sentiment analysis.

* They generate text by predicting the next most likely word in a sequence given the context. The output can seem very human and coherent.

* Examples of prominent LLMs include OpenAI's GPT-3, Google's BERT, and Microsoft's Turing-NLG.

* They have achieved state-of-the-art results on many NLP tasks but also have some weaknesses like lack of world knowledge and susceptibility to biases in the training data.

### Some key applications and future directions of LLMs include: 

* Natural language generation for dialogue, storytelling, and creative writing.

* Robust question answering and open-domain chatbots.

* Multimodal learning by incorporating images, speech, and other data types.

* Achieving human-level language understanding, which remains an open challenge.

# LLMs Educational Resources <a name="llms"></a> üìö 
* **START HERE**: "Transformers from Scratch", Brandon Rohrer, [[Website](https://e2eml.school/transformers.html)]

* **Stanford Transformers Class**: "CS25: Transformers United", Stanford, 2022, [[Website](https://web.stanford.edu/class/cs25/)]

* **Andrej Karpathy GPT Tutorial**: "Let's build GPT: from scratch, in code, spelled out." Andrej Karpathy, 2023 [[Youtube Video](https://www.youtube.com/watch?v=kCc8FmEb1nY)]

# Robotics Educational Resources <a name="robotics"></a> 
* **AI-Enabled Robotics Class**: "CS199: Stanford Robotics Independent Study", Stanford, 2023, [[Website](https://pupper-independent-study.readthedocs.io/en/latest/index.html)] 

## LLMs + Robotics Educational Resources <a name="llms-and-robotics"></a> 
* **Google's 2022 Research**: "Google Research, 2022 & beyond: Robotics", Google, 2023, [[Website](https://ai.googleblog.com/2023/02/google-research-2022-beyond-robotics.html)]

* **Controlling Robots Via Large Language Models**: "Controlling Robots Via Large Language Models", *Sanjiban Choudhury, CS 4756/5756, Cornell, 2023* [[Slides](https://www.cs.cornell.edu/courses/cs4756/2023sp/assets/slides_notes/lec26_slides.pdf)]

## Reasoning <a name="research-reasoning"></a>  
* **AutoTAMP**: "AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers", arXiv, June 2023. [[Paper](https://arxiv.org/pdf/2306.06531.pdf)]

* **LLM Designs Robots**: "CAN LARGE LANGUAGE MODELS DESIGN A ROBOT?", arXiv, Mar 2023. [[Paper](https://arxiv.org/pdf/2303.15324.pdf)]

* **PaLM-E**: "PaLM-E: An Embodied Multimodal Language Model", arXiV, Mar 2023. [[Paper](https://arxiv.org/abs/2303.03378)] [[Website](https://palm-e.github.io)] [[Demo](https://palm-e.github.io/#demo)]

* **RT-1**: "RT-1: Robotics Transformer for Real-World Control at Scale", arXiv, Dec 2022. [[Paper](https://arxiv.org/abs/2212.06817)] [[Code](https://github.com/google-research/robotics_transformer)] [[Website](https://robotics-transformer.github.io)]

* **ProgPrompt**: "Generating Situated Robot Task Plans using Large Language Models", arXiv, Sept 2022.  [[Paper](https://arxiv.org/abs/2209.11302)] [[Code Doesn't Really Exist here](https://github.com/progprompt/progprompt)] [[Website](https://progprompt.github.io)]

* **Code-As-Policies**: "Code as Policies: Language Model Programs for Embodied Control", arXiv, Sept 2022.  [[Paper](https://arxiv.org/abs/2209.07753)] [[Code](https://github.com/google-research/google-research/tree/master/code_as_policies)] [[Website](https://code-as-policies.github.io)]

* **Say-Can**: "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances", arXiv, Apr 2021. [[Paper](https://arxiv.org/abs/2204.01691)] [[Code](https://say-can.github.io/#open-source)] [[Website](https://say-can.github.io)]

* **Socratic**: "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language", arXiv, Apr 2021. [[Paper](https://arxiv.org/abs/2204.00598)] [[Code](https://socraticmodels.github.io/#code)] [[Website](https://socraticmodels.github.io)]

* **PIGLeT**: "PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World", ACL, Jun 2021. [[Paper](https://arxiv.org/abs/2201.07207)] [[Code](https://github.com/rowanz/piglet)] [[Website](https://rowanzellers.com/piglet/)]

# Free Cources Available üß† 

* [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
* [LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)
* [AI For Everyone](https://www.deeplearning.ai/courses/ai-for-everyone/)
* [Deep Learning Specialization](https://www.deeplearning.ai/courses/deep-learning-specialization/)
* [Machine Learning Specialization](https://www.deeplearning.ai/courses/machine-learning-specialization/)
* [Google AI for Anyone](https://www.edx.org/course/google-ai-for-anyone?index=product&queryID=20f255a72e55f01f6dbb7ba10089489d&position=3)
* [AI Foundations for Everyone Specialization](https://www.coursera.org/specializations/ai-foundations-for-everyone)

# AI Related Visualization üëÄ 

* [Tensorflow Playground](https://playground.tensorflow.org/) - Neural Network Training Visualization
* [Visualizing High-Dimensional Space](https://experiments.withgoogle.com/visualizing-high-dimensional-space) - Visualizing High-Dimensional Space
* [Word Embedding Visual Inspector](https://ronxin.github.io/wevi/) - Embedding Visualization

# The Best Article üìù 

* [Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712) - Contains various experiments of GPT-4, very detailed
* [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) - LLM model for performing language and decision-making tasks - ReAct
* [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761) - Let LLM Teach Yourself to Use the Tools
* [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer's paper
* [How Transformers Work](https://towardsdatascience.com/transformers-141e32e69591) 
* [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
* [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)

#

#### Curated By - Vansh Gehlot [[LinekdIn](https://www.linkedin.com/in/vanshgehlot/)] [[Twitter](https://twitter.com/VanshGehlotJDH)] [[Website](https://vanshgehlot.us)]
